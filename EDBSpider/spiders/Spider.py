import scrapy
from EDBSpider.items import EdbspiderItem
import HTMLParser


class EDBSpider(scrapy.Spider):
    name = 'EDBSpider'
    # allowed_domains = ['exploit-db.com']
    start_urls = [

        'https://old.exploit-db.com/webapps/',
        'https://old.exploit-db.com/remote/',
        'https://old.exploit-db.com/local/',
        'https://old.exploit-db.com/dos/'
    ]

    def parse(self, response):
        # print response.url
        selector = scrapy.Selector(response)
        list = selector.xpath('//table[@class="exploit_list bootstrap-wrapper"]/tbody/tr')
        item = EdbspiderItem()
        for piece in list:
            item['date'] = piece.xpath('td[@class="date"]/text()').re(r'(\d+-\d+-\d+)')  # Date
            item['id'] = piece.xpath('td[@class="description"]/a/@href').re(r'/(\d+)/')  # EDB-ID
            item['title'] = piece.xpath('td[@class="description"]/a/@title').extract()  # Title
            item['platform'] = piece.xpath('td[@class="platform"]/a/@title').extract()  # Platform
            item['author'] = piece.xpath('td[@class="author"]/a/@title').extract()  # Author
            item['type'] = response.url.split("/")[3]  # Type
            # item['category'] = piece.xpath('td[@class="description"]/a/@title').extract()[0].split(' - ')[-1]
            yield item

        next = selector.xpath('//div[@class="pagination"]').re(r'href="(.*?)">next')
        if next:
            html_parser = HTMLParser.HTMLParser()
            url = html_parser.unescape(next[0])
            yield scrapy.http.Request(url, callback=self.parse)
